{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd61a902",
   "metadata": {},
   "source": [
    "# Conceptos clave (visión profunda con CNN en CIFAR-10)\n",
    "\n",
    "## Mapa rápido (8–10 líneas)\n",
    "CIFAR-10 es un dataset de 60.000 imágenes RGB 32×32 organizadas en 10 clases (50.000 training, 10.000 test). Cada entrada tiene forma 32×32×3. Una CNN combina convoluciones (filtros locales) y pooling para extraer características espaciales jerárquicas; esto suele superar a una red totalmente densa porque las convoluciones explotan la invariancia por traslación (un objeto detectado en distintas posiciones sigue activando el mismo filtro) y comparten pesos espacialmente, reduciendo drásticamente parámetros frente a aplanar la imagen. Aplanar (flatten) al inicio ignora la estructura espacial y hace que la red necesite muchos más parámetros y datos para aprender patrones locales.\n",
    "\n",
    "## Convolución sin magia\n",
    "Un filtro (kernel) en Conv2D es una matriz de pesos de tamaño (k_h, k_w) que se aplica localmente sobre la imagen: por cada posición hace un producto elemento a elemento entre kernel y el parche de entrada y suma el resultado (más bias). Parámetros: tamaño del kernel (p. ej. 3×3), stride (paso entre posiciones), padding (valores añadidos en bordes: valid sin padding, same con padding para mantener tamaño), canales (kernel tiene dimensión adicional: in_channels y se producen out_channels filtros).\n",
    "\n",
    "## Ejemplo:\n",
    "Entrada 5×5, kernel 3×3, stride=1, padding=0 → salida 3×3.\n",
    "\n",
    "Si entrada single-channel y kernel = [[1,0,-1],[1,0,-1],[1,0,-1]] (detector de bordes), convolucionas y obtienes activación que resalta transiciones horizontales.\n",
    "Costo computacional aproximado por salida: k_h * k_w * in_channels multiplicaciones por cada ubicación y por cada filtro; total ≈ output_h * output_w * out_channels * k_h * k_w * in_channels.\n",
    "\n",
    "## Pooling y por qué importa (Max vs Average, 6–8 líneas)\n",
    "MaxPooling conserva la activación más fuerte en la ventana (preserva características discriminativas y es robusta a pequeñas traslaciones); AveragePooling promedia, suaviza y conserva información global pero puede atenuar rasgos fuertes. Max tiende a ayudar en clasificación porque mantiene las señales más relevantes; Average puede ayudar en tareas donde el conteo/energía promedio importa. Ambos reducen tamaño espacial y reducen sensibilidad al ruido local (al perder resolución). Ejemplo 2×2 (ventana): entrada [[1,2],[3,4]] → MaxPool → 4; AvgPool → (1+2+3+4)/4 = 2.5. Max aporta invarianza local mayor; Average es más informativa de la distribución local.\n",
    "\n",
    "## Arquitectura típica de una CNN simple (texto)\n",
    "Input 32×32×3 → [Conv(32,3×3) → ReLU → MaxPool(2×2)] × 2 → Flatten → Dense(128) → Dropout(0.5) → Dense(10, softmax)\n",
    "Función de cada bloque (1 línea cada uno): Conv(32) extrae 32 mapas de características locales; ReLU introduce no-linealidad; Pool reduce resolución y hace invariancia local; Flatten transforma mapas en vector para capa densa; Dense(128) combina características globales; Dropout regulariza evitando co-adaptación; Dense(10, softmax) produce probabilidades por clase.\n",
    "\n",
    "## Métrica y pérdida adecuadas\n",
    "\n",
    "Pérdida estándar: Categorical Crossentropy (para etiquetas one-hot).\n",
    "\n",
    "Métricas: accuracy (porcentaje de predicciones correctas) y, adicionalmente, precisión/recall por clase si interesa.\n",
    "Accuracy mide aciertos globales pero oculta errores por clase; la matriz de confusión muestra qué clases se confunden y es clave en CIFAR-10 para detectar pares problemáticos (p. ej. cat vs dog)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4f23f0",
   "metadata": {},
   "source": [
    "# Profundizar en lo imprescindible\n",
    "\n",
    "## Normalización y preparación de datos\n",
    "Dividimos por 255.0 para llevar valores de píxeles de [0,255] a [0,1]; esto acelera convergencia y mantiene la magnitud de activaciones en rangos numéricamente estables. Estandarizar por canal (restar media por canal y dividir por desviación estándar del canal) es recomendable cuando la distribución por canal no es uniforme y cuando usas redes profundas o técnicas sensibles a escala (batchnorm ayuda también). Efectos: normalizar/estandarizar mejora estabilidad del gradiente, permite usar learning rates más grandes y reduce oscilaciones; sin normalización el entrenamiento puede ser lento o inestable.\n",
    "\n",
    "## Baseline denso vs CNN (8–10 líneas)\n",
    "Un MLP que aplana la imagen convierte cada píxel en una entrada independiente → necesita muchas conexiones para modelar relaciones espaciales locales (parámetros explotan con tamaño de entrada). Una CNN comparte pesos y limita conexiones a vecindad local (sesgo inductivo espacial): asume que patrones útiles son locales y repetibles. Resultado: la CNN tiene menos parámetros para la misma capacidad de detección de patrones locales, es más robusta a traslaciones y menos sensible al ruido de fondo; el MLP puede memorizar ruido y requiere mucho más dato para generalizar. En resumen: CNN = inductive bias útil para imágenes → mejora sample efficiency y generalización.\n",
    "\n",
    "## Parámetros y capacidad (fórmula Conv2D)\n",
    "Para una capa Conv2D con kernel k_h × k_w, in_c canales de entrada y out_c filtros (salida):\n",
    "#parámetros = (k_h * k_w * in_c) * out_c + out_c (bias opcional).\n",
    "Mayor kernel o más filtros aumentan capacidad (más parámetros), suben tiempo de entrenamiento y aumentan riesgo de overfit; profundidad (más capas) aumenta capacidad no lineal y coste computacional pero permite aprender jerarquías: mejor práctica es crecer primero en filtros por bloque y usar kernels pequeños (3×3) apilados.\n",
    "## Regularización práctica (4 técnicas)\n",
    "1. Dropout — apaga unidades aleatoriamente en entrenamiento; reduce co-adaptación; usar en capas densas y/o conv con bajo ratio (p. ej. 0.2–0.5).\n",
    "2. L2 weight decay — penaliza pesos grandes; estabiliza y evita que la red memorize ruido.\n",
    "3. Data Augmentation — genera más ejemplos via flips, pequeñas rotaciones, traslaciones, jitter de color; reduce overfitting.\n",
    "4. Early Stopping — detener cuando la validación deja de mejorar; evita sobreentrenar al fin.\n",
    "Combina augment + weight decay + dropout frecuentemente; early stopping actúa como seguridad final.\n",
    "\n",
    "## Data Augmentation con cabeza (plan razonable para CIFAR-10)\n",
    "- Flips horizontales: sí (70–100%).\n",
    "- Rotaciones pequeñas: ±15° como máximo.\n",
    "- Traslaciones: hasta ±4 píxeles (10–12% del tamaño).\n",
    "- Jitter de color: brillo/contraste/saturación pequeños (±10–20%).\n",
    "- NO aplicar flip vertical (cambia semántica para classes como 'truck' o 'frog' en algunos casos), NO rotaciones 90° si la orientación importa. Límites: mantener transformaciones realistas para las clases.\n",
    "\n",
    "## Optimización y LR scheduling (SGD+momentum vs Adam, 6–8 líneas)\n",
    "- SGD + momentum: convergencia estable, buen control de generalización, requiere ajuste cuidadoso de LR y schedule.\n",
    "- Adam: adaptación automática del LR por parámetro, converge rápido y es robusto en inicialización; en algunas tareas generaliza ligeramente peor que SGD.\n",
    "Scheduler recomendado: ReduceLROnPlateau (reduce LR cuando la validación se estanca) o CosineDecay para decay suave por época. Señales para bajar LR: valid loss que no mejora por N épocas, valid accuracy estancada o aumento de val loss.\n",
    "\n",
    "## Curvas de aprendizaje: interpretación y patrones\n",
    "- Subajuste: train loss alto, val loss alto y similares → aumentar capacidad (más filtros/profundidad), entrenar más, reducir regularización.\n",
    "- Ajuste saludable: train loss baja y val loss baja, ambas mejorando → mantener, quizá entrenar más.\n",
    "- Sobreajuste: train loss baja pero val loss sube/diverge → aumentar regularización, aumentar augment, usar early stopping o más datos.\n",
    "\n",
    "## Matriz de confusión y clases difíciles\n",
    "Leer la matriz: filas = etiquetas verdaderas, columnas = predicciones (o viceversa según convención). Pairs propensos: cat vs dog, truck vs automobile, bird vs plane (depende de backgrounds). Mejora: aumento específico (más ejemplos/augment para clases confundidas), añadir capacidad (más profundidad) o usar focal loss si clases desbalanceadas. -->\n",
    "\n",
    "## Batch size y estabilidad\n",
    "Batch size grande (128+) reduce ruido del gradiente y permite usar LR mayor pero puede generalizar peor; batch pequeño (32) añade ruido de gradiente que a veces actúa como regularizador. En Colab (GPU limitada) un valor inicial razonable: batch = 64 (balance entre estabilidad, uso de memoria y velocidad por época).\n",
    "\n",
    "## Buenas prácticas de entrega (8–10 puntos)\n",
    "1. Código limpio y reproducible (README).\n",
    "2. Seed fijada (Python/Numpy/TF).\n",
    "3. ENVIRONMENT.md y requirements.txt.\n",
    "4. Logs de entrenamiento (tensorboard o CSV).\n",
    "5. Curvas train/valid (loss y accuracy).\n",
    "6. Matriz de confusión y análisis por clase.\n",
    "7. Tabla comparativa Dense vs CNN (parámetros, accuracy, tiempos).\n",
    "8. Resultados reproducibles (modelo final guardado).\n",
    "9. Imágenes de ejemplo de aciertos/errores.\n",
    "10. 5 hallazgos clave (qué funcionó, límite, overfitting, mejoras pendientes, tiempo de entrenamiento)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab603ab",
   "metadata": {},
   "source": [
    "# Proyecto en Colab — PROMPT 1 (implementación práctica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0233a05c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (699319992.py, line 6)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mpython notebooks/smoke_test.py\u001b[39m\n           ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# En Colab: instalar dependencias y montar repo (si quieres usar Drive)\n",
    "!pip install -q tensorflow==2.14.0 scikit-learn pyyaml matplotlib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b511092",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\migue\\Desktop\\borrar\\IA_P3_CIFAR10_Gonzalo_Millon\\.venv\\Lib\\site-packages\\keras\\src\\datasets\\cifar.py:18: VisibleDeprecationWarning: dtype(): align should be passed as Python or NumPy boolean but got `align=0`. Did you mean to pass a tuple to create a subarray type? (Deprecated NumPy 2.4)\n",
      "  d = cPickle.load(f, encoding=\"bytes\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formas: (50000, 32, 32, 3) (10000, 32, 32, 3)\n",
      "Guardado data_meta.json y shapes OK\n"
     ]
    }
   ],
   "source": [
    "# Pega esto en Colab (ajusta ruta a /content si subes carpeta)\n",
    "import os, json, hashlib, datetime, random\n",
    "import numpy as np\n",
    "random.seed(42); np.random.seed(42)\n",
    "\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "(x_train_full, y_train_full), (x_test, y_test) = cifar10.load_data()\n",
    "print(\"Formas:\", x_train_full.shape, x_test.shape)\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for tr, va in sss.split(x_train_full, y_train_full.ravel()):\n",
    "    x_train, x_valid = x_train_full[tr], x_train_full[va]\n",
    "    y_train, y_valid = y_train_full[tr], y_train_full[va]\n",
    "\n",
    "# Normalizar y one-hot\n",
    "x_train = x_train.astype('float32')/255.0\n",
    "x_valid = x_valid.astype('float32')/255.0\n",
    "x_test_norm = x_test.astype('float32')/255.0\n",
    "y_train_oh = to_categorical(y_train, 10)\n",
    "y_valid_oh = to_categorical(y_valid, 10)\n",
    "y_test_oh  = to_categorical(y_test, 10)\n",
    "\n",
    "# Hash primeras 1024 imágenes normalizadas\n",
    "first_n = min(1024, x_train.shape[0])\n",
    "subset = (x_train[:first_n]*255).astype('uint8')\n",
    "h = hashlib.sha256(subset.tobytes()).hexdigest()\n",
    "\n",
    "meta = {\n",
    "  \"x_train_shape\": x_train.shape,\n",
    "  \"x_valid_shape\": x_valid.shape,\n",
    "  \"x_test_shape\": x_test_norm.shape,\n",
    "  \"created_at\": datetime.datetime.utcnow().isoformat()+\"Z\",\n",
    "  \"sha256_first_{}_images\".format(first_n): h\n",
    "}\n",
    "open('results/data_meta.json','w').write(json.dumps(meta, indent=2))\n",
    "print(\"Guardado data_meta.json y shapes OK\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
